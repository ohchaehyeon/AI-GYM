{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lunge_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs #model 파일 변환을 위한 tenserflowjs 설치"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tECSfGygBr5V",
        "outputId": "ff2d6a25-9037-4a0a-c944-6960af677a83"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-3.12.0-py3-none-any.whl (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 19.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 71 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (2.7.0)\n",
            "Requirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (12.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.13.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.7.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.22.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.37.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.10.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.19.5)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.42.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.1)\n",
            "Installing collected packages: tensorflowjs\n",
            "Successfully installed tensorflowjs-3.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1pV6srrjxqb_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import layers # 딥러닝 모델을 위한 라이브러리들\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer # label 인코딩을 위한 라이브러리\n",
        "\n",
        "from google.colab import files  #csv 파일 colab 상으로 업로드를 위함"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 10\n",
        "np.random.seed(seed)\n",
        "\n",
        "csvFile = files.upload() #데이터 파일 업로드\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "dE3_SKU1yW-0",
        "outputId": "0de506a7-59fc-4343-f925-6e7fdc2413c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-389ca5d9-ffda-4efc-8527-c374180fcbc0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-389ca5d9-ffda-4efc-8527-c374180fcbc0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving lunge_dataset.csv to lunge_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "data = pd.read_csv(io.BytesIO(csvFile['lunge_dataset.csv']))\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "RnInwSipyn2F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "f17d7508-d65b-4dee-c41a-8919d1d861fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1de334e2-2797-4e06-bccb-ad8406134aaa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0_position_x</th>\n",
              "      <th>0_position_y</th>\n",
              "      <th>0_score</th>\n",
              "      <th>1_position_x</th>\n",
              "      <th>1_position_y</th>\n",
              "      <th>1_score</th>\n",
              "      <th>2_position_x</th>\n",
              "      <th>2_position_y</th>\n",
              "      <th>2_score</th>\n",
              "      <th>3_position_x</th>\n",
              "      <th>3_position_y</th>\n",
              "      <th>3_score</th>\n",
              "      <th>4_position_x</th>\n",
              "      <th>4_position_y</th>\n",
              "      <th>4_score</th>\n",
              "      <th>5_position_x</th>\n",
              "      <th>5_position_y</th>\n",
              "      <th>5_score</th>\n",
              "      <th>6_position_x</th>\n",
              "      <th>6_position_y</th>\n",
              "      <th>6_score</th>\n",
              "      <th>7_position_x</th>\n",
              "      <th>7_position_y</th>\n",
              "      <th>7_score</th>\n",
              "      <th>8_position_x</th>\n",
              "      <th>8_position_y</th>\n",
              "      <th>8_score</th>\n",
              "      <th>9_position_x</th>\n",
              "      <th>9_position_y</th>\n",
              "      <th>9_score</th>\n",
              "      <th>10_position_x</th>\n",
              "      <th>10_position_y</th>\n",
              "      <th>10_score</th>\n",
              "      <th>11_position_x</th>\n",
              "      <th>11_position_y</th>\n",
              "      <th>11_score</th>\n",
              "      <th>12_position_x</th>\n",
              "      <th>12_position_y</th>\n",
              "      <th>12_score</th>\n",
              "      <th>13_position_x</th>\n",
              "      <th>13_position_y</th>\n",
              "      <th>13_score</th>\n",
              "      <th>14_position_x</th>\n",
              "      <th>14_position_y</th>\n",
              "      <th>14_score</th>\n",
              "      <th>15_position_x</th>\n",
              "      <th>15_position_y</th>\n",
              "      <th>15_score</th>\n",
              "      <th>16_position_x</th>\n",
              "      <th>16_position_y</th>\n",
              "      <th>16_score</th>\n",
              "      <th>img_height</th>\n",
              "      <th>img_width</th>\n",
              "      <th>pose_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "      <td>3593.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>125.647258</td>\n",
              "      <td>52.626214</td>\n",
              "      <td>0.603521</td>\n",
              "      <td>128.285170</td>\n",
              "      <td>50.698918</td>\n",
              "      <td>0.539946</td>\n",
              "      <td>125.348314</td>\n",
              "      <td>50.970389</td>\n",
              "      <td>0.303186</td>\n",
              "      <td>132.438425</td>\n",
              "      <td>49.155375</td>\n",
              "      <td>0.597191</td>\n",
              "      <td>129.826210</td>\n",
              "      <td>49.033271</td>\n",
              "      <td>0.209920</td>\n",
              "      <td>135.114871</td>\n",
              "      <td>69.040654</td>\n",
              "      <td>0.785938</td>\n",
              "      <td>132.638967</td>\n",
              "      <td>67.851146</td>\n",
              "      <td>0.728137</td>\n",
              "      <td>136.032400</td>\n",
              "      <td>102.931333</td>\n",
              "      <td>0.710208</td>\n",
              "      <td>128.592495</td>\n",
              "      <td>101.764039</td>\n",
              "      <td>0.608559</td>\n",
              "      <td>128.303734</td>\n",
              "      <td>124.793593</td>\n",
              "      <td>0.743139</td>\n",
              "      <td>123.889947</td>\n",
              "      <td>123.850362</td>\n",
              "      <td>0.652840</td>\n",
              "      <td>134.234912</td>\n",
              "      <td>124.102741</td>\n",
              "      <td>0.782713</td>\n",
              "      <td>131.607801</td>\n",
              "      <td>123.881948</td>\n",
              "      <td>0.767109</td>\n",
              "      <td>129.256554</td>\n",
              "      <td>157.366942</td>\n",
              "      <td>0.739673</td>\n",
              "      <td>127.416128</td>\n",
              "      <td>157.986072</td>\n",
              "      <td>0.718072</td>\n",
              "      <td>135.056054</td>\n",
              "      <td>191.660105</td>\n",
              "      <td>0.611146</td>\n",
              "      <td>125.882367</td>\n",
              "      <td>191.310067</td>\n",
              "      <td>0.604312</td>\n",
              "      <td>247.154189</td>\n",
              "      <td>248.398553</td>\n",
              "      <td>0.629742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>65.905846</td>\n",
              "      <td>47.696374</td>\n",
              "      <td>0.374979</td>\n",
              "      <td>67.617182</td>\n",
              "      <td>47.971360</td>\n",
              "      <td>0.384951</td>\n",
              "      <td>67.178605</td>\n",
              "      <td>48.530000</td>\n",
              "      <td>0.283243</td>\n",
              "      <td>66.904964</td>\n",
              "      <td>49.713672</td>\n",
              "      <td>0.368809</td>\n",
              "      <td>65.920222</td>\n",
              "      <td>48.486672</td>\n",
              "      <td>0.217011</td>\n",
              "      <td>68.794831</td>\n",
              "      <td>51.676708</td>\n",
              "      <td>0.318915</td>\n",
              "      <td>64.794308</td>\n",
              "      <td>50.963244</td>\n",
              "      <td>0.312103</td>\n",
              "      <td>68.862069</td>\n",
              "      <td>55.438850</td>\n",
              "      <td>0.309432</td>\n",
              "      <td>63.597378</td>\n",
              "      <td>55.541480</td>\n",
              "      <td>0.273176</td>\n",
              "      <td>67.078513</td>\n",
              "      <td>57.411166</td>\n",
              "      <td>0.307417</td>\n",
              "      <td>67.081034</td>\n",
              "      <td>58.811116</td>\n",
              "      <td>0.273974</td>\n",
              "      <td>68.063091</td>\n",
              "      <td>62.770255</td>\n",
              "      <td>0.316002</td>\n",
              "      <td>65.035900</td>\n",
              "      <td>62.514450</td>\n",
              "      <td>0.309360</td>\n",
              "      <td>68.420147</td>\n",
              "      <td>71.315660</td>\n",
              "      <td>0.289332</td>\n",
              "      <td>64.470455</td>\n",
              "      <td>69.544812</td>\n",
              "      <td>0.284831</td>\n",
              "      <td>68.299546</td>\n",
              "      <td>84.747402</td>\n",
              "      <td>0.293662</td>\n",
              "      <td>66.272301</td>\n",
              "      <td>84.774753</td>\n",
              "      <td>0.281892</td>\n",
              "      <td>86.671873</td>\n",
              "      <td>100.855706</td>\n",
              "      <td>0.248933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-10.266961</td>\n",
              "      <td>-13.311756</td>\n",
              "      <td>0.000528</td>\n",
              "      <td>-7.899345</td>\n",
              "      <td>-10.793723</td>\n",
              "      <td>0.000737</td>\n",
              "      <td>-8.486717</td>\n",
              "      <td>-13.561060</td>\n",
              "      <td>0.000608</td>\n",
              "      <td>-7.927922</td>\n",
              "      <td>-16.848637</td>\n",
              "      <td>0.000386</td>\n",
              "      <td>-7.803750</td>\n",
              "      <td>-17.679083</td>\n",
              "      <td>0.000610</td>\n",
              "      <td>-7.514142</td>\n",
              "      <td>-15.425010</td>\n",
              "      <td>0.000674</td>\n",
              "      <td>-11.738182</td>\n",
              "      <td>-14.129022</td>\n",
              "      <td>0.000594</td>\n",
              "      <td>-8.927567</td>\n",
              "      <td>-6.215543</td>\n",
              "      <td>0.000537</td>\n",
              "      <td>-10.103379</td>\n",
              "      <td>-8.580183</td>\n",
              "      <td>0.000576</td>\n",
              "      <td>-9.849440</td>\n",
              "      <td>-5.287575</td>\n",
              "      <td>0.000613</td>\n",
              "      <td>-5.326314</td>\n",
              "      <td>-5.101714</td>\n",
              "      <td>0.000805</td>\n",
              "      <td>-6.494373</td>\n",
              "      <td>-6.097191</td>\n",
              "      <td>0.000802</td>\n",
              "      <td>-6.254012</td>\n",
              "      <td>-7.448987</td>\n",
              "      <td>0.000718</td>\n",
              "      <td>-10.041183</td>\n",
              "      <td>-6.990811</td>\n",
              "      <td>0.001133</td>\n",
              "      <td>-7.021356</td>\n",
              "      <td>-5.702689</td>\n",
              "      <td>0.000901</td>\n",
              "      <td>-6.753867</td>\n",
              "      <td>-0.903168</td>\n",
              "      <td>0.000942</td>\n",
              "      <td>-7.085725</td>\n",
              "      <td>-0.151686</td>\n",
              "      <td>0.000773</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>0.001182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>86.309809</td>\n",
              "      <td>15.218757</td>\n",
              "      <td>0.212194</td>\n",
              "      <td>88.496504</td>\n",
              "      <td>13.245644</td>\n",
              "      <td>0.105095</td>\n",
              "      <td>86.498243</td>\n",
              "      <td>13.189060</td>\n",
              "      <td>0.056498</td>\n",
              "      <td>94.213516</td>\n",
              "      <td>14.418104</td>\n",
              "      <td>0.210844</td>\n",
              "      <td>95.441537</td>\n",
              "      <td>14.344104</td>\n",
              "      <td>0.055953</td>\n",
              "      <td>94.953539</td>\n",
              "      <td>31.475383</td>\n",
              "      <td>0.732933</td>\n",
              "      <td>98.545126</td>\n",
              "      <td>30.787693</td>\n",
              "      <td>0.575600</td>\n",
              "      <td>95.792079</td>\n",
              "      <td>59.855303</td>\n",
              "      <td>0.544073</td>\n",
              "      <td>94.397707</td>\n",
              "      <td>58.315075</td>\n",
              "      <td>0.478940</td>\n",
              "      <td>88.227156</td>\n",
              "      <td>87.026990</td>\n",
              "      <td>0.660831</td>\n",
              "      <td>83.928036</td>\n",
              "      <td>85.837823</td>\n",
              "      <td>0.554181</td>\n",
              "      <td>94.968036</td>\n",
              "      <td>80.359777</td>\n",
              "      <td>0.814586</td>\n",
              "      <td>96.783137</td>\n",
              "      <td>80.430364</td>\n",
              "      <td>0.773001</td>\n",
              "      <td>91.871462</td>\n",
              "      <td>121.688665</td>\n",
              "      <td>0.717914</td>\n",
              "      <td>92.741628</td>\n",
              "      <td>121.152203</td>\n",
              "      <td>0.667928</td>\n",
              "      <td>85.866617</td>\n",
              "      <td>158.297105</td>\n",
              "      <td>0.410848</td>\n",
              "      <td>70.101535</td>\n",
              "      <td>157.932952</td>\n",
              "      <td>0.418164</td>\n",
              "      <td>224.000000</td>\n",
              "      <td>224.000000</td>\n",
              "      <td>0.554051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>112.807385</td>\n",
              "      <td>44.546719</td>\n",
              "      <td>0.768090</td>\n",
              "      <td>115.553650</td>\n",
              "      <td>41.327777</td>\n",
              "      <td>0.631925</td>\n",
              "      <td>111.071071</td>\n",
              "      <td>41.820636</td>\n",
              "      <td>0.220412</td>\n",
              "      <td>121.920102</td>\n",
              "      <td>38.935628</td>\n",
              "      <td>0.755917</td>\n",
              "      <td>115.267751</td>\n",
              "      <td>39.188794</td>\n",
              "      <td>0.137574</td>\n",
              "      <td>122.267565</td>\n",
              "      <td>62.418440</td>\n",
              "      <td>0.955530</td>\n",
              "      <td>116.283220</td>\n",
              "      <td>61.976132</td>\n",
              "      <td>0.882223</td>\n",
              "      <td>126.779004</td>\n",
              "      <td>100.299628</td>\n",
              "      <td>0.867189</td>\n",
              "      <td>114.536625</td>\n",
              "      <td>97.848652</td>\n",
              "      <td>0.677234</td>\n",
              "      <td>120.837165</td>\n",
              "      <td>120.924822</td>\n",
              "      <td>0.887337</td>\n",
              "      <td>111.446063</td>\n",
              "      <td>117.528768</td>\n",
              "      <td>0.733568</td>\n",
              "      <td>121.914823</td>\n",
              "      <td>118.701081</td>\n",
              "      <td>0.931170</td>\n",
              "      <td>116.823499</td>\n",
              "      <td>117.553774</td>\n",
              "      <td>0.912865</td>\n",
              "      <td>122.843127</td>\n",
              "      <td>138.137367</td>\n",
              "      <td>0.850714</td>\n",
              "      <td>117.231966</td>\n",
              "      <td>138.060429</td>\n",
              "      <td>0.811528</td>\n",
              "      <td>143.991296</td>\n",
              "      <td>178.662427</td>\n",
              "      <td>0.689005</td>\n",
              "      <td>128.156698</td>\n",
              "      <td>179.076320</td>\n",
              "      <td>0.732248</td>\n",
              "      <td>224.000000</td>\n",
              "      <td>224.000000</td>\n",
              "      <td>0.725555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>150.223397</td>\n",
              "      <td>74.084007</td>\n",
              "      <td>0.949511</td>\n",
              "      <td>151.630457</td>\n",
              "      <td>73.232821</td>\n",
              "      <td>0.926949</td>\n",
              "      <td>151.189658</td>\n",
              "      <td>73.059175</td>\n",
              "      <td>0.475900</td>\n",
              "      <td>152.954354</td>\n",
              "      <td>70.228991</td>\n",
              "      <td>0.929639</td>\n",
              "      <td>156.989566</td>\n",
              "      <td>70.090915</td>\n",
              "      <td>0.293061</td>\n",
              "      <td>155.439656</td>\n",
              "      <td>85.356328</td>\n",
              "      <td>0.986683</td>\n",
              "      <td>161.687171</td>\n",
              "      <td>84.151209</td>\n",
              "      <td>0.954660</td>\n",
              "      <td>160.232034</td>\n",
              "      <td>112.473462</td>\n",
              "      <td>0.932690</td>\n",
              "      <td>152.957267</td>\n",
              "      <td>108.373475</td>\n",
              "      <td>0.811548</td>\n",
              "      <td>152.895650</td>\n",
              "      <td>142.145500</td>\n",
              "      <td>0.958284</td>\n",
              "      <td>146.212444</td>\n",
              "      <td>141.035897</td>\n",
              "      <td>0.849070</td>\n",
              "      <td>155.311968</td>\n",
              "      <td>129.381143</td>\n",
              "      <td>0.972587</td>\n",
              "      <td>156.386288</td>\n",
              "      <td>128.754723</td>\n",
              "      <td>0.957890</td>\n",
              "      <td>153.838092</td>\n",
              "      <td>175.866661</td>\n",
              "      <td>0.930661</td>\n",
              "      <td>153.425967</td>\n",
              "      <td>178.772999</td>\n",
              "      <td>0.919819</td>\n",
              "      <td>162.439337</td>\n",
              "      <td>189.493438</td>\n",
              "      <td>0.861735</td>\n",
              "      <td>158.260425</td>\n",
              "      <td>189.335759</td>\n",
              "      <td>0.816406</td>\n",
              "      <td>224.000000</td>\n",
              "      <td>224.000000</td>\n",
              "      <td>0.791277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1081.321954</td>\n",
              "      <td>538.368225</td>\n",
              "      <td>0.999486</td>\n",
              "      <td>1098.261362</td>\n",
              "      <td>506.456284</td>\n",
              "      <td>0.999520</td>\n",
              "      <td>1076.728138</td>\n",
              "      <td>508.169279</td>\n",
              "      <td>0.998842</td>\n",
              "      <td>1188.386999</td>\n",
              "      <td>553.722955</td>\n",
              "      <td>0.996607</td>\n",
              "      <td>1138.191594</td>\n",
              "      <td>546.774088</td>\n",
              "      <td>0.988279</td>\n",
              "      <td>1198.598884</td>\n",
              "      <td>705.500238</td>\n",
              "      <td>0.999279</td>\n",
              "      <td>1118.825029</td>\n",
              "      <td>690.935184</td>\n",
              "      <td>0.999133</td>\n",
              "      <td>1192.034042</td>\n",
              "      <td>912.653814</td>\n",
              "      <td>0.998297</td>\n",
              "      <td>1135.051223</td>\n",
              "      <td>905.334832</td>\n",
              "      <td>0.998548</td>\n",
              "      <td>1147.227677</td>\n",
              "      <td>1091.100556</td>\n",
              "      <td>0.996224</td>\n",
              "      <td>1145.576151</td>\n",
              "      <td>1090.954738</td>\n",
              "      <td>0.996618</td>\n",
              "      <td>1138.790294</td>\n",
              "      <td>1074.753460</td>\n",
              "      <td>0.999712</td>\n",
              "      <td>1109.835332</td>\n",
              "      <td>1067.460316</td>\n",
              "      <td>0.999561</td>\n",
              "      <td>882.294428</td>\n",
              "      <td>1165.097272</td>\n",
              "      <td>0.998665</td>\n",
              "      <td>877.663208</td>\n",
              "      <td>1169.338625</td>\n",
              "      <td>0.997380</td>\n",
              "      <td>1136.342950</td>\n",
              "      <td>1428.612677</td>\n",
              "      <td>0.993824</td>\n",
              "      <td>901.968173</td>\n",
              "      <td>1458.176676</td>\n",
              "      <td>0.981816</td>\n",
              "      <td>1667.000000</td>\n",
              "      <td>2500.000000</td>\n",
              "      <td>0.973330</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1de334e2-2797-4e06-bccb-ad8406134aaa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1de334e2-2797-4e06-bccb-ad8406134aaa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1de334e2-2797-4e06-bccb-ad8406134aaa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       0_position_x  0_position_y  ...    img_width   pose_score\n",
              "count   3593.000000   3593.000000  ...  3593.000000  3593.000000\n",
              "mean     125.647258     52.626214  ...   248.398553     0.629742\n",
              "std       65.905846     47.696374  ...   100.855706     0.248933\n",
              "min      -10.266961    -13.311756  ...    75.000000     0.001182\n",
              "25%       86.309809     15.218757  ...   224.000000     0.554051\n",
              "50%      112.807385     44.546719  ...   224.000000     0.725555\n",
              "75%      150.223397     74.084007  ...   224.000000     0.791277\n",
              "max     1081.321954    538.368225  ...  2500.000000     0.973330\n",
              "\n",
              "[8 rows x 54 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 셋 설명\n",
        "자체 수집한 런지 사진 데이터를 PoseNet 모델을 통해 <br>\n",
        "0.코   \n",
        "1.왼쪽 눈  \n",
        "2.오른쪽 눈  \n",
        "3.왼쪽 귀  \n",
        "4.오른쪽 귀  \n",
        "5.왼쪽 어깨  \n",
        "6.오른쪽 어깨  \n",
        "7.왼쪽 팔꿈치  \n",
        "8.오른쪽 팔꿈치  \n",
        "9.왼쪽 손목  \n",
        "10.오른쪽 손목  \n",
        "11.왼쪽 골반 부위  \n",
        "12.오른쪽 골반 부위  \n",
        "13.왼쪽 무릎  \n",
        "14.오른쪽 무릎  \n",
        "15.왼쪽 발목  \n",
        "16.오른쪽 발목  \n",
        "\n",
        "각각의 x,y 좌표와 신뢰도점수, 이미지 크기와 ,전체 신뢰도 점수를 구해 데이터 셋으로 만들었습니다.  \n",
        "\n",
        "[출처) 포즈예측 | Tensorflow Lite](https://www.tensorflow.org/lite/examples/pose_estimation/overview?hl=ko)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8peoGdyXKA4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(17):\n",
        "  str_i = str(i)\n",
        "  data[str_i+'_position_x'] = data[str_i+'_position_x'] / data['img_width']\n",
        "  data[str_i+'_position_y'] = data[str_i+'_position_y'] / data['img_height']\n",
        "\n",
        "# 이미지 크기로 각 x,y 좌표를 나누어 이미지 크기에 구애 받지 않는 데이터셋으로 변환\n",
        "label = data['label']\n",
        "features = data.drop(['label'],axis=1).drop(['img_width'],axis=1).drop(['img_height'],axis=1) # label과 feature 분리"
      ],
      "metadata": {
        "id": "yOFhV3ciziFw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x, test_x, train_y, test_y = train_test_split(features, label, test_size=0.3)"
      ],
      "metadata": {
        "id": "lOchuIF30ybw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "                            keras.Input(shape = [len(train_x.keys())]),\n",
        "                            layers.Dense(64, activation='relu'),\n",
        "                            layers.Dense(64, activation='relu'),\n",
        "                            layers.Dense(64, activation='relu'),\n",
        "                            layers.Dense(3, activation = 'softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      loss='categorical_crossentropy',\n",
        "      optimizer = 'adam',\n",
        "      metrics=['acc'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "ezBASZvi1OUj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "f9W_OOcc1gHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36db6af4-aa1c-4291-fa45-65458aceff03"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                3392      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,907\n",
            "Trainable params: 11,907\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "labels = mlb.fit_transform(label.str.split(\",\")) #Label One-Hot Encoding"
      ],
      "metadata": {
        "id": "_qCsIpzC3EAh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x, test_x, train_y, test_y = train_test_split(features, labels, test_size=0.3)  #Train set과 Test set 구분"
      ],
      "metadata": {
        "id": "-5h-Jznu4-ty"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import validation\n",
        "model.fit(train_x,train_y, epochs = 30)"
      ],
      "metadata": {
        "id": "t-l-7hWc650J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55bc8801-b4cd-4233-8660-2ae6333871e2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "79/79 [==============================] - 1s 2ms/step - loss: 0.5402 - acc: 0.8258\n",
            "Epoch 2/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.1866 - acc: 0.9396\n",
            "Epoch 3/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.1473 - acc: 0.9527\n",
            "Epoch 4/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.1367 - acc: 0.9571\n",
            "Epoch 5/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.1201 - acc: 0.9630\n",
            "Epoch 6/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.1200 - acc: 0.9610\n",
            "Epoch 7/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0995 - acc: 0.9650\n",
            "Epoch 8/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.1081 - acc: 0.9630\n",
            "Epoch 9/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0889 - acc: 0.9694\n",
            "Epoch 10/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0759 - acc: 0.9761\n",
            "Epoch 11/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0756 - acc: 0.9765\n",
            "Epoch 12/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0780 - acc: 0.9722\n",
            "Epoch 13/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0785 - acc: 0.9742\n",
            "Epoch 14/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0692 - acc: 0.9777\n",
            "Epoch 15/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0846 - acc: 0.9702\n",
            "Epoch 16/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0781 - acc: 0.9746\n",
            "Epoch 17/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0528 - acc: 0.9821\n",
            "Epoch 18/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0530 - acc: 0.9825\n",
            "Epoch 19/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0555 - acc: 0.9809\n",
            "Epoch 20/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0453 - acc: 0.9857\n",
            "Epoch 21/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0559 - acc: 0.9829\n",
            "Epoch 22/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0398 - acc: 0.9897\n",
            "Epoch 23/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0394 - acc: 0.9885\n",
            "Epoch 24/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0462 - acc: 0.9849\n",
            "Epoch 25/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0399 - acc: 0.9885\n",
            "Epoch 26/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0328 - acc: 0.9901\n",
            "Epoch 27/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0431 - acc: 0.9833\n",
            "Epoch 28/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0353 - acc: 0.9881\n",
            "Epoch 29/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0279 - acc: 0.9913\n",
            "Epoch 30/30\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.0269 - acc: 0.9944\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7af76227d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_x, test_y) #테스트 데이터로 검증\n",
        "mlb.classes_ # 출력 형태"
      ],
      "metadata": {
        "id": "iCJocpBo7GPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f1b736f-b693-4b4e-dd1c-952b9850cff8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 0s 1ms/step - loss: 0.0541 - acc: 0.9852\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['lunge', 'nothing', 'standingside'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트를 위한 코드\n",
        "# csvTestFile =  files.upload() \n",
        "# test = pd.read_csv(io.BytesIO(csvTestFile['csv_downloadfile (9).csv']))\n",
        "# test\n",
        "# proba = model.predict(test)\n",
        "# idx = np.argmax(proba)\n",
        "# proba"
      ],
      "metadata": {
        "id": "XuL-Gx63_RCO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save-Model\n"
      ],
      "metadata": {
        "id": "sLswOVAPF1-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflowjs as tfjs #저장된 모델을 불러오기 위함\n",
        "tfjs.converters.save_keras_model(model,artifacts_dir=\"./lunge_model.json\")\n"
      ],
      "metadata": {
        "id": "PGZbaRHdAMK8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('lunge_model.h5')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "2e8aN5I1BavI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986df6f1-2716-4ebd-be12-1496d34b97a8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                3392      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,907\n",
            "Trainable params: 11,907\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yzOedSD7F7Nr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}